{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/site-packages (21.0.1)\n",
      "Collecting pip\n",
      "  Using cached pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.0.1\n",
      "    Uninstalling pip-21.0.1:\n",
      "      Successfully uninstalled pip-21.0.1\n",
      "Successfully installed pip-21.3.1\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5 pytz-2022.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: zipp, importlib-resources, tqdm\n",
      "Successfully installed importlib-resources-5.4.0 tqdm-4.64.0 zipp-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/site-packages (21.3.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (59.3.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.6/site-packages (0.36.2)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.3.0\n",
      "    Uninstalling setuptools-59.3.0:\n",
      "      Successfully uninstalled setuptools-59.3.0\n",
      "Successfully installed setuptools-59.6.0 wheel-0.37.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install sklearn\n",
    "!pip install openpyxl\n",
    "# !pip install fiftyone==0.15.1\n",
    "# !pip install fiftyone-brain==0.8.2\n",
    "# !pip install fiftyone-db==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import openpyxl\n",
    "import ast\n",
    "# import fiftyone as fo\n",
    "# import fiftyone.zoo as foz\n",
    "from yaml.loader import SafeLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Open the file and load the file\n",
    "with open(os.path.join(os.getcwd(),'user_trg_config_verified_img.yaml')) as f:\n",
    "    data = yaml.load(f, Loader=SafeLoader)\n",
    "    trg_class = data['trg_class']\n",
    "    user_path = data['user_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['box', 'plate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### images download\n",
    "\n",
    "main_path = os.getcwd()\n",
    "\n",
    "# DATA_PATH = os.path.join(user_path,f\"fiftyone/open-images-v6\")\n",
    "IMG_PATH = os.path.join(main_path,f\"bangkok_photos\")\n",
    "ORG_LABEL_PATH = os.path.join(main_path,f\"runs/detect/combined/labels\")\n",
    "VERIFIED_IMG_PATH = os.path.join(main_path,f\"verified_photos\")\n",
    "if not os.path.exists(VERIFIED_IMG_PATH):\n",
    "    os.mkdir(VERIFIED_IMG_PATH)\n",
    "VERIFIED_AL1_IMG_PATH = os.path.join(main_path,f\"verified_al1_photos\")\n",
    "if not os.path.exists(VERIFIED_AL1_IMG_PATH):\n",
    "    os.mkdir(VERIFIED_AL1_IMG_PATH)\n",
    "\n",
    "## now we're suppposed to be under project folder\n",
    "OUTPUT_PATH = os.path.join(main_path, f\"custom_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(list_of_two_lists):\n",
    "    final_list = list(set(list_of_two_lists[0]) | set(list_of_two_lists[1]))\n",
    "    return final_list\n",
    "\n",
    "def intersect(list_of_two_lists):\n",
    "    final_list = [i for i in list_of_two_lists[0] if i in list_of_two_lists[1]]\n",
    "    return final_list\n",
    "\n",
    "## define data processing function\n",
    "def process_data(train_test_dict, data_type=\"train\"):\n",
    "    \n",
    "    images = [i for i in train_test_dict[data_type]]\n",
    "    for image_name in images:\n",
    "        src_filepath = os.path.join(ORG_LABEL_PATH, f\"{image_name}.txt\")\n",
    "        txt_output_filepath = os.path.join(OUTPUT_PATH, f\"labels/{data_type}/{image_name}.txt\")\n",
    "        \n",
    "        img_file = open(src_filepath, \"r\")\n",
    "        lines = img_file.readlines()\n",
    "        lines = [ast.literal_eval(line.rstrip()) for line in lines]\n",
    "        lines = [line[:-1] for line in lines]\n",
    "        verified_lines = []\n",
    "        for line in lines:\n",
    "            for class_id, class_name in enumerate(trg_class):\n",
    "#                 if not (\n",
    "#                             (\n",
    "#                                 (image_name in exception_class_dict[trg_class[class_id]]) or \n",
    "#                                 (image_name in exception_combined_class_dict['should_not_pass'])\n",
    "#                             )\n",
    "#                             and (line[0]==class_id)\n",
    "#                         ):\n",
    "#                     verified_lines.append(line)\n",
    "                if not ((image_name in exception_combined_class_dict['should_not_pass']) and \n",
    "                        (line[0]==class_id)):\n",
    "                    verified_lines.append(line)\n",
    "                    \n",
    "        img_file.close()\n",
    "        \n",
    "        if len(verified_lines)>0:\n",
    "            if len(verified_lines)==1:\n",
    "                print(f\"only 1 detection: {image_name}\")\n",
    "            np.savetxt(\n",
    "                txt_output_filepath,\n",
    "                lines,\n",
    "                fmt=[\"%d\",\"%f\",\"%f\",\"%f\",\"%f\"]\n",
    "            )\n",
    "\n",
    "        shutil.copyfile(\n",
    "            os.path.join(IMG_PATH, f\"{image_name}.png\"),\n",
    "            os.path.join(OUTPUT_PATH, f\"images/{data_type}/{image_name}.jpg\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_list:['/root/openimages-custom-yolov5/custom_data', '/root/openimages-custom-yolov5/custom_data/images', '/root/openimages-custom-yolov5/custom_data/images/train', '/root/openimages-custom-yolov5/custom_data/images/validation', '/root/openimages-custom-yolov5/custom_data/labels', '/root/openimages-custom-yolov5/custom_data/labels/train', '/root/openimages-custom-yolov5/custom_data/labels/validation']\n",
      "path:/root/openimages-custom-yolov5/custom_data\n",
      "path:/root/openimages-custom-yolov5/custom_data/images\n",
      "path:/root/openimages-custom-yolov5/custom_data/images/train\n",
      "path:/root/openimages-custom-yolov5/custom_data/images/validation\n",
      "path:/root/openimages-custom-yolov5/custom_data/labels\n",
      "path:/root/openimages-custom-yolov5/custom_data/labels/train\n",
      "path:/root/openimages-custom-yolov5/custom_data/labels/validation\n",
      "len verified both: 752\n",
      "test_size:113\n",
      "train_size:639\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ### create custom data folder with below tree structure\n",
    "\n",
    "    # custom_data\n",
    "    #   images\n",
    "    #       train\n",
    "    #       validation\n",
    "    #   labels\n",
    "    #       train\n",
    "    #       validation\n",
    "\n",
    "    custom_data_path = os.path.join(main_path,f\"custom_data\")\n",
    "    path_list = [custom_data_path]\n",
    "    for fldr in ['images','labels']:\n",
    "        path = os.path.join(custom_data_path,f\"{fldr}\")\n",
    "        path_list.append(path)\n",
    "        for data_type in ['train','validation']:\n",
    "            path = os.path.join(custom_data_path,f\"{fldr}/{data_type}\")\n",
    "            path_list.append(path)\n",
    "    \n",
    "    print(f\"path_list:{path_list}\")\n",
    "    for path in path_list:\n",
    "        print(f\"path:{path}\")\n",
    "        if path == custom_data_path: \n",
    "            ## remove custom_data path if exist\n",
    "            if os.path.exists(path):\n",
    "                shutil.rmtree(path)\n",
    "            os.mkdir(path)\n",
    "        else:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "\n",
    "    exception_combined_class_dict = {}\n",
    "    exception_class_dict = {}\n",
    "    exception_dict = {}\n",
    "    exception_filepath = os.path.join(os.getcwd(),'detection_exceptions.xlsx')\n",
    "    for i,class_name in enumerate(trg_class):\n",
    "    #     print(class_name)\n",
    "        df_exception = pd.read_excel(exception_filepath,\n",
    "                                     sheet_name=class_name,\n",
    "                                     engine='openpyxl')\n",
    "\n",
    "        exception_class_dict[class_name] = []\n",
    "        exception_dict[class_name] = {}\n",
    "        for col in [i for i in df_exception.columns.values]:\n",
    "    #         print(col)\n",
    "            df_exception[col] = df_exception[col].apply(lambda x: None if (pd.isnull(x) or \n",
    "                                                        (str(x).replace('.0','').isdigit()==False)) else \n",
    "                                                        'item_'+str(x).replace('.0',''))\n",
    "\n",
    "\n",
    "            exception_combined_class_dict[col] = {}\n",
    "            exception_col_list = []\n",
    "            \n",
    "            exception_dict[class_name][col] = [i for i in df_exception[col].unique() if not pd.isnull(i)]\n",
    "            for element in df_exception[col].unique():\n",
    "                exception_list = []\n",
    "                if not (pd.isnull(element) or (element in exception_list)):\n",
    "                    exception_list.append(element)\n",
    "                    exception_class_dict[class_name].append(element)\n",
    "\n",
    "                    for img in exception_list:\n",
    "                        if img not in exception_col_list:\n",
    "                            exception_col_list.append(img)\n",
    "\n",
    "            exception_combined_class_dict[col] = exception_col_list\n",
    "    \n",
    "    \n",
    "    ## get relevant image ids\n",
    "    imagefile_path = IMG_PATH\n",
    "    image_ids = [re.split('\\.',f )[0] for f in os.listdir(imagefile_path) if \n",
    "                 os.path.isfile(os.path.join(imagefile_path, f))]\n",
    "    \n",
    "    \n",
    "    to_reannotate_intersect_list = intersect([exception_dict[class_name]['to_reannotate'] for class_name in trg_class])\n",
    "    verfied_at_least_1_class_list = [i for i in image_ids if \n",
    "                                     ((i not in exception_combined_class_dict['should_not_pass']) and \n",
    "                                      (i not in to_reannotate_intersect_list))]\n",
    "    verified_both_list = [i for i in image_ids if \n",
    "                         (i not in union([exception_combined_class_dict['should_not_pass'],\n",
    "                                          exception_combined_class_dict['to_reannotate']]))]\n",
    "    print(f\"len verified both: {len(verified_both_list)}\")\n",
    "    \n",
    "#     test_size = int(round(float(len(verfied_at_least_1_class_list))*0.2,0))\n",
    "# train_size = int(len(verfied_at_least_1_class_list) - test_size)\n",
    "    test_size = int(round(float(len(verified_both_list))*0.15,0))\n",
    "    train_size = int(len(verified_both_list) - test_size)\n",
    "    print(f\"test_size:{test_size}\")\n",
    "    print(f\"train_size:{train_size}\")\n",
    "    \n",
    "#     train_ids, validation_ids = train_test_split(verfied_at_least_1_class_list, \n",
    "#                                            train_size=train_size, \n",
    "#                                            test_size=test_size)\n",
    "    train_ids, validation_ids = train_test_split(verified_both_list, \n",
    "                                           train_size=train_size, \n",
    "                                           test_size=test_size)\n",
    "    \n",
    "    train_test_dict = {\"train\":train_ids, \"validation\":validation_ids}\n",
    "                                     \n",
    "    for data_type in [\"train\",\"validation\"]:\n",
    "        \n",
    "        ### moving images and labels to custom_data path\n",
    "        \n",
    "        ### edit labels to fit yolo format\n",
    "        process_data(train_test_dict, data_type=data_type)\n",
    "\n",
    "        ## dump dict object into yaml file\n",
    "        custom = {\n",
    "            'train': \"custom_data/images/train\",\n",
    "            'val': \"custom_data/images/validation\",\n",
    "            'nc': len(trg_class),\n",
    "            'names': trg_class\n",
    "        }\n",
    "\n",
    "        with open('custom.yaml', 'w') as f:\n",
    "            data = yaml.dump(custom, f)\n",
    "            \n",
    "#     for image_name in verfied_at_least_1_class_list:\n",
    "#         shutil.copyfile(\n",
    "#                     os.path.join(IMG_PATH, f\"{image_name}.png\"),\n",
    "#                     os.path.join(VERIFIED_IMG_PATH, f\"{image_name}.jpg\")\n",
    "#                 )\n",
    "    for image_name in verified_both_list:\n",
    "        shutil.copyfile(\n",
    "                    os.path.join(IMG_PATH, f\"{image_name}.png\"),\n",
    "                    os.path.join(VERIFIED_IMG_PATH, f\"{image_name}.jpg\")\n",
    "                )\n",
    "        \n",
    "    for image_name in verfied_at_least_1_class_list:\n",
    "    shutil.copyfile(\n",
    "                os.path.join(IMG_PATH, f\"{image_name}.png\"),\n",
    "                os.path.join(VERIFIED_AL1_IMG_PATH, f\"{image_name}.jpg\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f161cf723975c91024d06f6cededc8f2b4727dcee5d0fc14309f22330025f3f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
